{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4edbcdc-be44-4697-8574-b1d5b0f5a66b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T05:48:26.205706Z",
     "iopub.status.busy": "2024-07-10T05:48:26.205551Z",
     "iopub.status.idle": "2024-07-10T05:48:26.317020Z",
     "shell.execute_reply": "2024-07-10T05:48:26.315883Z",
     "shell.execute_reply.started": "2024-07-10T05:48:26.205695Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "INFO:root:NaNs before dropping: \n",
      "Open                  0\n",
      "High                  0\n",
      "Low                   0\n",
      "Close                 0\n",
      "Adj Close             0\n",
      "Volume                0\n",
      "RSI                  14\n",
      "MACD                 33\n",
      "MACD_signal          33\n",
      "Bollinger_upper     145\n",
      "Bollinger_middle    145\n",
      "Bollinger_lower     145\n",
      "dtype: int64\n",
      "INFO:root:NaNs after dropping: \n",
      "Open                0\n",
      "High                0\n",
      "Low                 0\n",
      "Close               0\n",
      "Adj Close           0\n",
      "Volume              0\n",
      "RSI                 0\n",
      "MACD                0\n",
      "MACD_signal         0\n",
      "Bollinger_upper     0\n",
      "Bollinger_middle    0\n",
      "Bollinger_lower     0\n",
      "dtype: int64\n",
      "ERROR:root:Preprocessed data is empty after dropping NaNs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas_ta as ta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Function to fetch price data\n",
    "def fetch_price_data(symbol, interval='1h', days=6):\n",
    "    end_date = pd.to_datetime('today')\n",
    "    start_date = end_date - pd.Timedelta(days=days)  # Fetching data for the last 6 days\n",
    "    try:\n",
    "        data = yf.download(symbol, start=start_date, end=end_date, interval=interval)\n",
    "        if data.empty:\n",
    "            raise ValueError(f\"No data found for {symbol} in the last {days} days.\")\n",
    "    except ValueError as e:\n",
    "        logger.error(e)\n",
    "        return None\n",
    "    return data\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_data(df):\n",
    "    # Technical indicators using pandas_ta\n",
    "    df['RSI'] = ta.rsi(df['Close'], length=14)\n",
    "    macd = ta.macd(df['Close'])\n",
    "    df['MACD'] = macd['MACD_12_26_9']\n",
    "    df['MACD_signal'] = macd['MACDs_12_26_9']\n",
    "    bbands = ta.bbands(df['Close'])\n",
    "    df['Bollinger_upper'] = bbands.get('BBU_20_2.0', np.nan)\n",
    "    df['Bollinger_middle'] = bbands.get('BBM_20_2.0', np.nan)\n",
    "    df['Bollinger_lower'] = bbands.get('BBL_20_2.0', np.nan)\n",
    "\n",
    "    # Assigning data types\n",
    "    df = df.astype({\n",
    "        'Open': 'float64',\n",
    "        'High': 'float64',\n",
    "        'Low': 'float64',\n",
    "        'Close': 'float64',\n",
    "        'Adj Close': 'float64',\n",
    "        'Volume': 'int64',\n",
    "        'RSI': 'float64',\n",
    "        'MACD': 'float64',\n",
    "        'MACD_signal': 'float64',\n",
    "        'Bollinger_upper': 'float64',\n",
    "        'Bollinger_middle': 'float64',\n",
    "        'Bollinger_lower': 'float64'\n",
    "    })\n",
    "\n",
    "    # Logging the number of NaNs\n",
    "    logger.info(f\"NaNs before dropping: \\n{df.isna().sum()}\")\n",
    "\n",
    "    # Drop rows with NaN values\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Logging the number of NaNs after dropping\n",
    "    logger.info(f\"NaNs after dropping: \\n{df.isna().sum()}\")\n",
    "\n",
    "    # If data is empty after dropping NaNs, log an error and return None\n",
    "    if df.empty:\n",
    "        logger.error(\"Preprocessed data is empty after dropping NaNs.\")\n",
    "        return None, None\n",
    "\n",
    "    # Scaling data\n",
    "    scaler = MinMaxScaler()\n",
    "    df[['Close', 'RSI', 'MACD', 'MACD_signal', 'Bollinger_upper', 'Bollinger_middle', 'Bollinger_lower']] = scaler.fit_transform(\n",
    "        df[['Close', 'RSI', 'MACD', 'MACD_signal', 'Bollinger_upper', 'Bollinger_middle', 'Bollinger_lower']]\n",
    "    )\n",
    "    \n",
    "    return df, scaler\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(data, seq_length, target_shift):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data) - seq_length - target_shift):\n",
    "        x = data.iloc[i:(i + seq_length)].values\n",
    "        y = data.iloc[i + seq_length + target_shift]['Close']\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys).reshape(-1, 1)\n",
    "\n",
    "# Define the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(7, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(X_train, y_train, model, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        inputs = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "        targets = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).squeeze()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Parameters\n",
    "    symbol = 'BTC-USD'\n",
    "    seq_length = 50\n",
    "    target_shift = 10\n",
    "\n",
    "    # Fetch and prepare data\n",
    "    price_data = fetch_price_data(symbol, interval='1h', days=6)\n",
    "    if price_data is None:\n",
    "        logger.error(f\"No data found for {symbol}. Skipping further processing.\")\n",
    "        return\n",
    "    try:\n",
    "        processed_data, scaler = preprocess_data(price_data)\n",
    "        if processed_data is None:\n",
    "            return\n",
    "    except ValueError as e:\n",
    "        logger.error(e)\n",
    "        return\n",
    "\n",
    "    # Log the number of rows in the processed data\n",
    "    logger.info(f\"Number of rows in processed data: {len(processed_data)}\")\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    train_size = int(len(processed_data) * 0.8)\n",
    "    train_data, test_data = processed_data[:train_size], processed_data[train_size:]\n",
    "\n",
    "    # Create sequences\n",
    "    X_train, y_train = create_sequences(train_data, seq_length, target_shift)\n",
    "    X_test, y_test = create_sequences(test_data, seq_length, target_shift)\n",
    "\n",
    "    if len(X_train) == 0 or len(X_test) == 0:\n",
    "        logger.error(\"Not enough data to create sequences. Skipping further processing.\")\n",
    "        return\n",
    "\n",
    "    # Initialize model, criterion, and optimizer\n",
    "    model = MLP().to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train model\n",
    "    train_model(X_train, y_train, model, criterion, optimizer, num_epochs=100)\n",
    "\n",
    "    # Evaluate model\n",
    "    model.eval()\n",
    "    inputs = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    targets = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "    outputs = model(inputs).squeeze()\n",
    "    loss = criterion(outputs, targets)\n",
    "    print(f'Test Loss: {loss.item():.4f}')\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ae30c-f21e-4df5-933f-216b54605530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a76f060-ba17-47d0-b2a1-6eae429a1578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
