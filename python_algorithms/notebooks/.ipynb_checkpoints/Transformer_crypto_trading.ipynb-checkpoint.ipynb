{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a32b7e15-efe9-4b0f-a73d-da009aef36bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T02:58:04.873832Z",
     "iopub.status.busy": "2024-07-10T02:58:04.873498Z",
     "iopub.status.idle": "2024-07-10T02:58:08.604672Z",
     "shell.execute_reply": "2024-07-10T02:58:08.604077Z",
     "shell.execute_reply.started": "2024-07-10T02:58:04.873792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Trying to download data from CryptoCompare for BTC-USD...\n",
      "[ERROR] CCCAGG market does not exist for this coin pair (BTC-USD-USD)\n",
      "Data downloaded from CryptoCompare.\n",
      "Trying to download data from Yahoo Finance for BTC-USD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded from Yahoo Finance.\n",
      "Data downloaded and saved to crypto_data.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/crypto-trading/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'close'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 133\u001b[0m\n\u001b[1;32m    130\u001b[0m download_crypto_data(crypto_symbol, binance_symbol, start_date, end_date, interval, downloaded_file)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Preprocess data\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownloaded_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocessed_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Load preprocessed data\u001b[39;00m\n\u001b[1;32m    136\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(preprocessed_file)\n",
      "Cell \u001b[0;32mIn[1], line 103\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(file_name, output_file)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe data frame is empty. Please check the data download step.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Calculate additional features\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMA_10\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mrolling(window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    104\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMA_50\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mrolling(window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    105\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[0;32m~/.pyenv/versions/crypto-trading/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.pyenv/versions/crypto-trading/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'close'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import cryptocompare\n",
    "import yfinance as yf\n",
    "from binance.client import Client\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Function to download data\n",
    "def download_crypto_data(symbol, binance_symbol, start_date, end_date, interval, file_name):\n",
    "    data = None\n",
    "\n",
    "    # Try downloading from CryptoCompare\n",
    "    try:\n",
    "        print(f\"Trying to download data from CryptoCompare for {symbol}...\")\n",
    "        all_data = []\n",
    "        start_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "        end_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "        while start_dt < end_dt:\n",
    "            next_end_dt = min(start_dt + timedelta(days=60), end_dt)\n",
    "            data = cryptocompare.get_historical_price_minute(symbol, currency='USD', limit=2000, toTs=int(next_end_dt.timestamp()))\n",
    "            if data:\n",
    "                all_data.extend(data)\n",
    "            start_dt = next_end_dt\n",
    "            time.sleep(1)  # Sleep to avoid rate limit issues\n",
    "        if all_data:\n",
    "            data = pd.DataFrame(all_data)\n",
    "            data['time'] = pd.to_datetime(data['time'], unit='s')\n",
    "            data.set_index('time', inplace=True)\n",
    "        print(\"Data downloaded from CryptoCompare.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download data from CryptoCompare: {e}\")\n",
    "\n",
    "    # If CryptoCompare fails, try yfinance\n",
    "    if data is None or data.empty:\n",
    "        try:\n",
    "            print(f\"Trying to download data from Yahoo Finance for {symbol}...\")\n",
    "            yf_data = yf.download(symbol, start=start_date, end=end_date, interval=interval)\n",
    "            if not yf_data.empty:\n",
    "                yf_data.index = pd.to_datetime(yf_data.index)\n",
    "                data = yf_data\n",
    "            print(\"Data downloaded from Yahoo Finance.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download data from Yahoo Finance: {e}\")\n",
    "\n",
    "    # If yfinance fails, fallback to Binance\n",
    "    if data is None or data.empty:\n",
    "        try:\n",
    "            print(f\"Trying to download data from Binance for {binance_symbol}...\")\n",
    "            client = Client()\n",
    "            all_data = []\n",
    "            start_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "            end_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "            while start_dt < end_dt:\n",
    "                next_end_dt = min(start_dt + timedelta(days=60), end_dt)\n",
    "                klines = client.get_historical_klines(binance_symbol, interval, start_dt.strftime(\"%d %b, %Y\"), next_end_dt.strftime(\"%d %b, %Y\"))\n",
    "                if klines:\n",
    "                    for kline in klines:\n",
    "                        all_data.append({\n",
    "                            'time': datetime.fromtimestamp(kline[0] / 1000),\n",
    "                            'open': float(kline[1]),\n",
    "                            'high': float(kline[2]),\n",
    "                            'low': float(kline[3]),\n",
    "                            'close': float(kline[4]),\n",
    "                            'volume': float(kline[5])\n",
    "                        })\n",
    "                start_dt = next_end_dt\n",
    "                time.sleep(1)  # Sleep to avoid rate limit issues\n",
    "            if all_data:\n",
    "                data = pd.DataFrame(all_data)\n",
    "                data.set_index('time', inplace=True)\n",
    "            print(\"Data downloaded from Binance.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download data from Binance: {e}\")\n",
    "\n",
    "    if data is not None and not data.empty:\n",
    "        data.to_csv(file_name)\n",
    "        print(f\"Data downloaded and saved to {file_name}\")\n",
    "    else:\n",
    "        print(\"Failed to download data from all sources.\")\n",
    "\n",
    "# Function to preprocess data\n",
    "def preprocess_data(file_name, output_file):\n",
    "    # Load the data\n",
    "    data = pd.read_csv(file_name)\n",
    "\n",
    "    # Print the columns to debug\n",
    "    print(\"Columns in the downloaded data:\", data.columns)\n",
    "\n",
    "    # Check if data is loaded properly\n",
    "    if data.empty:\n",
    "        raise ValueError(\"The data frame is empty. Please check the data download step.\")\n",
    "\n",
    "    # Rename columns if necessary\n",
    "    if 'Close' in data.columns:\n",
    "        data.rename(columns={'Close': 'close', 'Volume': 'volume'}, inplace=True)\n",
    "\n",
    "    # Calculate additional features\n",
    "    data['MA_10'] = data['close'].rolling(window=10).mean()\n",
    "    data['MA_50'] = data['close'].rolling(window=50).mean()\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Check if there are enough data points after calculating moving averages\n",
    "    if data.empty:\n",
    "        raise ValueError(\"The data frame is empty after calculating moving averages. Please check the date range and data availability.\")\n",
    "\n",
    "    # Preprocess the data\n",
    "    features = ['close', 'volume', 'MA_10', 'MA_50']\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data[features])\n",
    "    \n",
    "    # Save preprocessed data\n",
    "    pd.DataFrame(scaled_data, columns=features).to_csv(output_file, index=False)\n",
    "    print(f\"Data preprocessed and saved to {output_file}\")\n",
    "\n",
    "# Define parameters for data acquisition and preprocessing\n",
    "crypto_symbol = 'BTC-USD'\n",
    "binance_symbol = 'BTCUSDT'\n",
    "start_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "interval = '1m'\n",
    "downloaded_file = 'crypto_data.csv'\n",
    "preprocessed_file = 'preprocessed_crypto_data.csv'\n",
    "\n",
    "# Download data\n",
    "download_crypto_data(crypto_symbol, binance_symbol, start_date, end_date, interval, downloaded_file)\n",
    "\n",
    "# Preprocess data\n",
    "preprocess_data(downloaded_file, preprocessed_file)\n",
    "\n",
    "# Load preprocessed data\n",
    "data = pd.read_csv(preprocessed_file)\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(data, seq_length, target_shift):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data) - seq_length - target_shift):\n",
    "        x = data[i:i + seq_length]\n",
    "        y = data[i + seq_length + target_shift][0]  # Target is the close price\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "seq_length = 50\n",
    "target_shift = 3  # Predict 3 intervals ahead (15 minutes ahead)\n",
    "X, y = create_sequences(data.values, seq_length, target_shift)\n",
    "X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y = torch.tensor(y, dtype=torch.float32).unsqueeze(1).to(device)  # Add dimension to match input shape\n",
    "\n",
    "# Train-test split\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Define the Transformer model class\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, num_heads, hidden_size, output_size):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=input_size, nhead=num_heads, dim_feedforward=hidden_size, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "# Adjust input size to be divisible by num_heads\n",
    "num_features = X.shape[2]\n",
    "num_heads = 2\n",
    "assert num_features % num_heads == 0, \"Number of features must be divisible by the number of heads\"\n",
    "\n",
    "model = TransformerModel(num_features, num_layers=2, num_heads=num_heads, hidden_size=50, output_size=1).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    outputs = model(X_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "predicted = model(X_test).detach().cpu().numpy()\n",
    "actual = y_test.cpu().numpy()\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(actual, label='Actual Price')\n",
    "plt.plot(predicted, label='Predicted Price')\n",
    "plt.title('Actual vs Predicted Prices')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3006e4a-ec40-4dce-83f6-2b8181d4d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary libraries\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import os\n",
    "# import yfinance as yf\n",
    "\n",
    "# # Define a function to download data if it doesn't exist\n",
    "# def download_crypto_data(symbol, start_date, end_date, file_name):\n",
    "#     if not os.path.exists(file_name):\n",
    "#         print(f\"Downloading data for {symbol} from {start_date} to {end_date}...\")\n",
    "#         data = yf.download(symbol, start=start_date, end=end_date, interval='1d')\n",
    "#         data.to_csv(file_name)\n",
    "#         print(f\"Data downloaded and saved to {file_name}\")\n",
    "#     else:\n",
    "#         print(f\"Data file {file_name} already exists. Skipping download.\")\n",
    "\n",
    "# # Parameters for data acquisition\n",
    "# crypto_symbol = 'BTC-USD'\n",
    "# start_date = '2018-01-01'\n",
    "# end_date = '2023-12-31'\n",
    "# output_file = 'crypto_data.csv'\n",
    "\n",
    "# # Download data\n",
    "# download_crypto_data(crypto_symbol, start_date, end_date, output_file)\n",
    "\n",
    "# # Load the data\n",
    "# data = pd.read_csv(output_file)\n",
    "\n",
    "# # Calculate additional features\n",
    "# data['MA_10'] = data['Close'].rolling(window=10).mean()\n",
    "# data['MA_50'] = data['Close'].rolling(window=50).mean()\n",
    "# data = data.dropna()\n",
    "\n",
    "# # Preprocess the data\n",
    "# features = ['Close', 'Volume', 'MA_10', 'MA_50']\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaled_data = scaler.fit_transform(data[features])\n",
    "\n",
    "# # Create sequences with shifted target\n",
    "# def create_sequences(data, seq_length, target_shift):\n",
    "#     xs = []\n",
    "#     ys = []\n",
    "#     for i in range(len(data) - seq_length - target_shift):\n",
    "#         x = data[i:i + seq_length]\n",
    "#         y = data[i + seq_length + target_shift][0]  # Target is the close price\n",
    "#         xs.append(x)\n",
    "#         ys.append(y)\n",
    "#     return np.array(xs), np.array(ys)\n",
    "\n",
    "# seq_length = 50\n",
    "# target_shift = 3  # Predict 3 days ahead\n",
    "# X, y = create_sequences(scaled_data, seq_length, target_shift)\n",
    "# X = torch.tensor(X, dtype=torch.float32)\n",
    "# y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# # Train-test split\n",
    "# train_size = int(len(X) * 0.8)\n",
    "# X_train, X_test = X[:train_size], X[train_size:]\n",
    "# y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# # Define the Transformer model class\n",
    "# class TransformerModel(nn.Module):\n",
    "#     def __init__(self, input_size, num_layers, num_heads, hidden_size, output_size):\n",
    "#         super(TransformerModel, self).__init__()\n",
    "#         self.encoder_layer = nn.TransformerEncoderLayer(d_model=input_size, nhead=num_heads, dim_feedforward=hidden_size)\n",
    "#         self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "#         self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.transformer_encoder(x)\n",
    "#         x = self.fc(x[:, -1, :])\n",
    "#         return x\n",
    "\n",
    "# # Adjust input size to be divisible by num_heads\n",
    "# num_features = X.shape[2]\n",
    "# num_heads = 2\n",
    "# assert num_features % num_heads == 0, \"Number of features must be divisible by the number of heads\"\n",
    "\n",
    "# model = TransformerModel(num_features, num_layers=2, num_heads=num_heads, hidden_size=50, output_size=1)\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# num_epochs = 100\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     outputs = model(X_train)\n",
    "#     optimizer.zero_grad()\n",
    "#     loss = criterion(outputs, y_train)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     if (epoch + 1) % 10 == 0:\n",
    "#         print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# # Evaluate the model\n",
    "# model.eval()\n",
    "# predicted = model(X_test).detach().numpy()\n",
    "# actual = y_test.numpy()\n",
    "\n",
    "# # Plot the results\n",
    "# plt.figure(figsize=(10,6))\n",
    "# plt.plot(actual, label='Actual Price')\n",
    "# plt.plot(predicted, label='Predicted Price')\n",
    "# plt.title('Actual vs Predicted Prices')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8a07e8-19df-4a33-9d5b-c199f932ca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import osFileNotFoundError: [Errno 2] No such file or directory: 'download_crypto_data.py'\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Function to dynamically load a script and execute it\n",
    "def load_script(script_path):\n",
    "    with open(script_path) as f:\n",
    "        code = compile(f.read(), script_path, 'exec')\n",
    "        exec(code, globals())\n",
    "\n",
    "# Load the scripts\n",
    "load_script('download_crypto_data.py')\n",
    "load_script('preprocess_crypto_data.py')\n",
    "\n",
    "# Define parameters for data acquisition and preprocessing\n",
    "crypto_symbol = 'BTC-USD'\n",
    "binance_symbol = 'BTCUSDT'\n",
    "start_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "interval = '1m'\n",
    "downloaded_file = 'crypto_data.csv'\n",
    "preprocessed_file = 'preprocessed_crypto_data.csv'\n",
    "\n",
    "# Download data\n",
    "download_crypto_data(crypto_symbol, binance_symbol, start_date, end_date, interval, downloaded_file)\n",
    "\n",
    "# Preprocess data\n",
    "preprocess_data(downloaded_file, preprocessed_file)\n",
    "\n",
    "# Load preprocessed data\n",
    "data = pd.read_csv(preprocessed_file)\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(data, seq_length, target_shift):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data) - seq_length - target_shift):\n",
    "        x = data[i:i + seq_length]\n",
    "        y = data[i + seq_length + target_shift][0]  # Target is the close price\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "seq_length = 50\n",
    "target_shift = 3  # Predict 3 intervals ahead (15 minutes ahead)\n",
    "X, y = create_sequences(data.values, seq_length, target_shift)\n",
    "X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "y = torch.tensor(y, dtype=torch.float32).unsqueeze(1).to(device)  # Add dimension to match input shape\n",
    "\n",
    "# Train-test split\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Define the Transformer model class\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, num_heads, hidden_size, output_size):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=input_size, nhead=num_heads, dim_feedforward=hidden_size, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "# Adjust input size to be divisible by num_heads\n",
    "num_features = X.shape[2]\n",
    "num_heads = 2\n",
    "assert num_features % num_heads == 0, \"Number of features must be divisible by the number of heads\"\n",
    "\n",
    "model = TransformerModel(num_features, num_layers=2, num_heads=num_heads, hidden_size=50, output_size=1).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    outputs = model(X_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "predicted = model(X_test).detach().cpu().numpy()\n",
    "actual = y_test.cpu().numpy()\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(actual, label='Actual Price')\n",
    "plt.plot(predicted, label='Predicted Price')\n",
    "plt.title('Actual vs Predicted Prices')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd0f024-cb37-4bcc-8cf6-e77d5d6fc63e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
